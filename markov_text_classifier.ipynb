{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will classify poems of two authors by creating two Markov models and then feeding their predictions into a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\n",
    "  'edgar_allan_poe.txt',\n",
    "  'robert_frost.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data into lists\n",
    "input_texts = []\n",
    "labels = []\n",
    "\n",
    "for label, f in enumerate(input_files):\n",
    "  print(f\"{f} corresponds to label {label}\")\n",
    "\n",
    "  for line in open(f):\n",
    "    line = line.rstrip().lower()\n",
    "    if line:\n",
    "      # remove punctuation\n",
    "      line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "      input_texts.append(line)\n",
    "      labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, input_test, Y_train, Y_test = train_test_split(input_texts, labels, random_state=42)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "X_train = []\n",
    "tok2ind = {}\n",
    "current_ind = 0\n",
    "\n",
    "for line in input_train:\n",
    "    tokenised_line = word_tokenize(line)\n",
    "    X_train.append(tokenised_line)\n",
    "    for tok in tokenised_line:\n",
    "        if tok not in vocab:\n",
    "            vocab.append(tok)\n",
    "            tok2ind[tok] = current_ind\n",
    "            current_ind += 1\n",
    "\n",
    "ind2tok = {val: it for it, val in tok2ind.items()}\n",
    "\n",
    "D = len(vocab)\n",
    "print(f'Vocab length: {D}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [word_tokenize(line) for line in input_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert tokens to indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ind = [[tok2ind[tok] for tok in line] for line in X_train]\n",
    "# for test set, we give a special index to tokens which are not in the train vocabulary - D+1\n",
    "X_test_ind = [[tok2ind[tok] if tok in list(tok2ind.keys()) else D for tok in line] for line in X_test]\n",
    "\n",
    "vocab_ind = [tok2ind[tok] for tok in vocab]\n",
    "\n",
    "N = len(X_train_ind) # number of train sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate Pi_i and A_ij using simple counting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts(state_1 = i)\n",
    "counts_initial_0 = np.zeros(D+1) # +1 to cover the special tokens not present in train set\n",
    "counts_initial_1 = np.zeros(D+1) # +1 to cover the special tokens not present in train set\n",
    "# counts(i->j)\n",
    "counts_transition_0 = np.zeros((D+1, D+1))\n",
    "counts_transition_1 = np.zeros((D+1, D+1))\n",
    "# counts(i)\n",
    "counts_words_0 = np.zeros(D+1)\n",
    "counts_words_1 = np.zeros(D+1)\n",
    "\n",
    "# proceed line by line\n",
    "for line_no in range(N):\n",
    "    line = X_train_ind[line_no]\n",
    "    label = Y_train[line_no] # get the label so that we know which Markov model we are training\n",
    "\n",
    "    transitions = [line[i:i+2] for i in range(0, len(line)-1)]\n",
    "    # [6, 34, 97, 12] -> [[6, 34], [34, 97], [97, 12]]\n",
    "\n",
    "    for ii, jj in transitions:\n",
    "        if label:\n",
    "            counts_transition_1[ii, jj] += 1 # fill in the counts(i->j) and counts(i) matrices\n",
    "            counts_words_1[ii] += 1\n",
    "\n",
    "            if ii == transitions[0][0]: # fill in the counts(state_1 = i) matrix\n",
    "                counts_initial_1[ii] += 1\n",
    "\n",
    "            if jj == transitions[-1][-1]: # counts_words_1[ii] += 1 does not cover the last token in the line, so handle it here\n",
    "                counts_words_1[jj] += 1\n",
    "        # and same for the other Markov process\n",
    "        else:\n",
    "            counts_transition_0[ii, jj] += 1\n",
    "            counts_words_0[ii] += 1\n",
    "\n",
    "            if ii == transitions[0][0]:\n",
    "                counts_initial_0[ii] += 1\n",
    "\n",
    "            if jj == transitions[-1][-1]:\n",
    "                counts_words_0[jj] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we work with logs for better numerical stability (i.e. underflow)\n",
    "# take log(term1) - log(term2), not log(term1/term2)\n",
    "# finally, we do 'add-one' smoothing to prevent taking log(0)\n",
    "log_pi_0 = np.log(counts_initial_0 + 1) - np.log(N + (D+1))\n",
    "log_pi_1 = np.log(counts_initial_1 + 1) - np.log(N + (D+1))\n",
    "\n",
    "log_A_0 = np.log(counts_transition_0 + 1) - np.log(counts_words_0 + (D+1))\n",
    "log_A_1 = np.log(counts_transition_1 + 1) - np.log(counts_words_1 + (D+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our trained Markov models for class 0 and 1. We need to plug them into Bayes rule. We want:\n",
    "\n",
    "p(class|x) = p(x|class) * p(class) / p(x)\n",
    "\n",
    "We ignore the evidence p(x), because we're just interested in the argmax of the LHS. We need to compute the prior p(class). This is unless we are sure that the prior is uniform, but if we have unbalanced classes, this is not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the prior\n",
    "n_0 = (Y_train == 0).sum()\n",
    "n_1 = (Y_train == 1).sum()\n",
    "\n",
    "print(f'n_0: {n_0}, n_1: {n_1}')\n",
    "\n",
    "log_prior_0 = np.log(n_0) - np.log(n_0 + n_1)\n",
    "log_prior_1 = np.log(n_1) - np.log(n_0 + n_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_prob_Markov(line: list[int], log_pi, log_A, log_prior = 0):\n",
    "    \"\"\"Compute log probs of a sequence according to Markov assumptions.\n",
    "    line needs to be a list of tokens turned into indices, e.g. 'I like dogs' -> [34, 9, 51]\n",
    "    \"\"\"\n",
    "    transition_probs = 0\n",
    "    transitions = [line[i:i+2] for i in range(0, len(line)-1)]\n",
    "\n",
    "    for ii, jj in transitions:\n",
    "        transition_probs += log_A[ii, jj]\n",
    "    \n",
    "    initial_prob = log_pi[line[0]]\n",
    "    \n",
    "    return initial_prob + transition_probs + log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_log_prob_Markov(X_test_ind[0], log_pi_0, log_A_0, log_prior_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_Markov(line: list[int]):\n",
    "    prob_0 = compute_log_prob_Markov(line, log_pi_0, log_A_0, log_prior_0)\n",
    "    prob_1 = compute_log_prob_Markov(line, log_pi_1, log_A_1, log_prior_1)\n",
    "\n",
    "    if prob_0 > prob_1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(lines: list[list[int]], labels: list[int]):\n",
    "    preds = np.array([classify_Markov(line) for line in lines])\n",
    "\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy on train set: {evaluate(X_train_ind, Y_train)}')\n",
    "print(f'Accuracy on test set: {evaluate(X_test_ind, Y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
